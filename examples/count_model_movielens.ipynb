{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1971f6cf",
   "metadata": {},
   "source": [
    "## Application of count models on Movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6985b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext watermark\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f571098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from subprocess import call\n",
    "from pybpr import *\n",
    "import pybpr\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from dataclasses import dataclass\n",
    "from pprint import pprint\n",
    "from typing import List, Tuple, Union, Optional, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9df1be78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ctripp/zazzle/pybpr/examples\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcd21924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>214</td>\n",
       "      <td>259</td>\n",
       "      <td>255</td>\n",
       "      <td>4</td>\n",
       "      <td>874724710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83965</td>\n",
       "      <td>259</td>\n",
       "      <td>286</td>\n",
       "      <td>4</td>\n",
       "      <td>874724727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43027</td>\n",
       "      <td>259</td>\n",
       "      <td>298</td>\n",
       "      <td>4</td>\n",
       "      <td>874724754</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21396</td>\n",
       "      <td>259</td>\n",
       "      <td>185</td>\n",
       "      <td>4</td>\n",
       "      <td>874724781</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82655</td>\n",
       "      <td>259</td>\n",
       "      <td>173</td>\n",
       "      <td>4</td>\n",
       "      <td>874724843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  user_id  item_id  rating  timestamp  positive\n",
       "0    214      259      255       4  874724710         1\n",
       "1  83965      259      286       4  874724727         1\n",
       "2  43027      259      298       4  874724754         1\n",
       "3  21396      259      185       4  874724781         1\n",
       "4  82655      259      173       4  874724843         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "# df = load_movielens_data('ml-1m')\n",
    "df = pybpr.load_movielens_data('ml-100k')\n",
    "df.sort_values(['timestamp', 'user_id'], inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df['positive'] = (df['rating'] >= 4).astype(np.int8)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10fd7614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26399</td>\n",
       "      <td>259</td>\n",
       "      <td>288</td>\n",
       "      <td>3</td>\n",
       "      <td>874724905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4029</td>\n",
       "      <td>259</td>\n",
       "      <td>405</td>\n",
       "      <td>3</td>\n",
       "      <td>874725120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>76434</td>\n",
       "      <td>259</td>\n",
       "      <td>1074</td>\n",
       "      <td>3</td>\n",
       "      <td>874725264</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>97222</td>\n",
       "      <td>851</td>\n",
       "      <td>687</td>\n",
       "      <td>2</td>\n",
       "      <td>874728168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>69246</td>\n",
       "      <td>851</td>\n",
       "      <td>696</td>\n",
       "      <td>3</td>\n",
       "      <td>874728338</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  user_id  item_id  rating  timestamp  positive\n",
       "7   26399      259      288       3  874724905         0\n",
       "11   4029      259      405       3  874725120         0\n",
       "12  76434      259     1074       3  874725264         0\n",
       "16  97222      851      687       2  874728168         0\n",
       "17  69246      851      696       3  874728338         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['positive'] == 0].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eec38ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 total entries. 20.0% = 20000\n",
      "test_timestamp: 878963305\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "test_proportion = 0.2\n",
    "\n",
    "total = len(df)\n",
    "slice_index = int(test_proportion * total)\n",
    "print(f'{total} total entries. {test_proportion*100}% = {slice_index}')\n",
    "\n",
    "# train_df = df.iloc[:slice_index].sort_values(['user_id', 'timestamp']).reset_index()\n",
    "# test_df = df.iloc[slice_index:].sort_values(['user_id', 'timestamp']).reset_index()\n",
    "train_df = df.iloc[:slice_index]\n",
    "test_df = df.iloc[slice_index:]\n",
    "test_timestamp = test_df['timestamp'].iloc[0]\n",
    "print(f'test_timestamp: {test_timestamp}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29580f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20022</th>\n",
       "      <td>96941</td>\n",
       "      <td>181</td>\n",
       "      <td>280</td>\n",
       "      <td>4</td>\n",
       "      <td>878963381</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20023</th>\n",
       "      <td>24271</td>\n",
       "      <td>181</td>\n",
       "      <td>974</td>\n",
       "      <td>4</td>\n",
       "      <td>878963417</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20042</th>\n",
       "      <td>11930</td>\n",
       "      <td>267</td>\n",
       "      <td>475</td>\n",
       "      <td>5</td>\n",
       "      <td>878970368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20043</th>\n",
       "      <td>9176</td>\n",
       "      <td>267</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>878970399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20044</th>\n",
       "      <td>45928</td>\n",
       "      <td>267</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>878970427</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  user_id  item_id  rating  timestamp  positive\n",
       "20022  96941      181      280       4  878963381         1\n",
       "20023  24271      181      974       4  878963417         1\n",
       "20042  11930      267      475       5  878970368         1\n",
       "20043   9176      267      250       5  878970399         1\n",
       "20044  45928      267      100       5  878970427         1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df['positive'] == 1].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8478cdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from count_model.link_counter import LinkCounter\n",
    "from count_model.uniform_prior_model import UniformPriorModel\n",
    "from count_model.window_counter import WindowCounter\n",
    "from count_model.permutation_counter import PermutationCounter\n",
    "from count_model.link_count_data import LinkCountData\n",
    "\n",
    "positive_counter = PermutationCounter(LinkCounter())\n",
    "negative_counter = PermutationCounter(LinkCounter())\n",
    "both_counter = PermutationCounter(LinkCounter())\n",
    "dest_counter = LinkCounter()\n",
    "# counter = WindowCounter(LinkCounter(), 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d61be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_action_tuple(row, positive=None):\n",
    "    return int(row['item_id']), (\n",
    "        bool(row['positive'] == 1) if positive is None else positive\n",
    "    )\n",
    "\n",
    "def make_item_sequence(df):\n",
    "    return (row['item_id'] for row_index, row in df.iterrows())\n",
    "\n",
    "\n",
    "def make_action_sequence(df):\n",
    "    return (make_action_tuple(row, None) for row_index, row in df.iterrows())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35283aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_groups = df.groupby('user_id')\n",
    "for user_id, group in user_groups:\n",
    "    user_df = user_groups.get_group(user_id)\n",
    "    # positive_interactions = user_df[user_df['positive'] >= 1]\n",
    "    for idx, row in user_df.iterrows():\n",
    "        dest_counter.observe_link(make_action_tuple(row, False), make_action_tuple(row))\n",
    "    positive_counter.observe_sequence(\n",
    "        make_action_sequence(user_df[user_df['positive'] == 1])\n",
    "    )\n",
    "    negative_counter.observe_sequence(\n",
    "        make_action_sequence(user_df[user_df['positive'] == 0])\n",
    "    )\n",
    "    both_counter.observe_sequence(make_action_sequence(user_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "705cc0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability_model = UniformPriorModel(counter.link_counter, 1.1, 1e5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5ea22f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pos_neg_action(action):\n",
    "    return (action[0], False), (action[0], True)\n",
    "\n",
    "\n",
    "def make_opposite_action(action):\n",
    "    return (action[0], not action[1])\n",
    "\n",
    "\n",
    "def compute_with_links(\n",
    "    assesment_func,\n",
    "    dest_counter,\n",
    "    link_counter,\n",
    "    sources,\n",
    "    dest,\n",
    "):\n",
    "    negative_dest, positive_dest = make_pos_neg_action(dest)\n",
    "\n",
    "    dest_count = dest_counter.get_link_count(negative_dest, positive_dest)\n",
    "\n",
    "    source_counts = []\n",
    "    for source in sources:\n",
    "        opp_source = make_opposite_action(source)\n",
    "\n",
    "        source_counts.append(\n",
    "            (\n",
    "                source,\n",
    "                link_counter.get_link_count(source, positive_dest),\n",
    "                link_counter.get_link_count(source, negative_dest),\n",
    "                link_counter.get_link_count(opp_source, positive_dest),\n",
    "                link_counter.get_link_count(opp_source, negative_dest),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    p = assesment_func(positive_dest, LinkCountData(dest_count.count, dest_count.total), source_counts)\n",
    "    if not dest[1]:\n",
    "        p = 1.0 - p\n",
    "    return np.log(p)\n",
    "\n",
    "\n",
    "def make_assessment_function(prob_func, dest_counter, link_counter):\n",
    "    return lambda sources, dest: compute_with_links(\n",
    "        prob_func,\n",
    "        dest_counter,\n",
    "        link_counter,\n",
    "        sources,\n",
    "        dest,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "524f0581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_naive_bayes_posterior(\n",
    "    prior_numerator,\n",
    "    prior_denominator,\n",
    "    pos_feature_prior_numerator,\n",
    "    pos_feature_prior_denominator,\n",
    "    neg_feature_prior_numerator,\n",
    "    neg_feature_prior_denominator,\n",
    "):\n",
    "    def compute(\n",
    "        dest,\n",
    "        dest_count,\n",
    "        source_counts,\n",
    "    ):\n",
    "        dest_prior = (prior_numerator + dest_count.count) / (\n",
    "            prior_denominator + dest_count.total\n",
    "        )\n",
    "        pos_acc = np.log(dest_prior)\n",
    "        neg_acc = np.log(1.0 - dest_prior)\n",
    "        for source_count in source_counts:\n",
    "            (\n",
    "                source,\n",
    "                source_to_pos_dest,\n",
    "                source_to_neg_dest,\n",
    "                neg_source_to_pos_dest,\n",
    "                neg_source_to_neg_dest,\n",
    "            ) = source_count\n",
    "            # P(source | dest) -> # source to dest / (# total both source to dest)\n",
    "            #  link_count(source, dest) / get_source_data(dest).total\n",
    "            cond_prob = (pos_feature_prior_numerator + source_to_pos_dest.count) / (\n",
    "                pos_feature_prior_denominator\n",
    "                + source_to_pos_dest.count\n",
    "                + neg_source_to_pos_dest.count\n",
    "            )\n",
    "            pos_acc += np.log(cond_prob)\n",
    "\n",
    "            # source to -dest / total +/- source to -dest\n",
    "            neg_cond_prob = (neg_feature_prior_numerator + source_to_neg_dest.count) / (\n",
    "                neg_feature_prior_denominator\n",
    "                + source_to_neg_dest.count\n",
    "                + neg_source_to_neg_dest.count\n",
    "            )\n",
    "            neg_acc += np.log(neg_cond_prob)\n",
    "            # evidence = (feature_prior_numerator source_count.source_count.count / source_count.source_count.total)\n",
    "            # ep += dest_prior * cond_prob\n",
    "            # s = source_count.source_count\n",
    "            # ep += np.log((s.count + feature_prior_numerator) / (feature_prior_denominator + s.total))\n",
    "        pos = np.exp(pos_acc)\n",
    "        neg = np.exp(neg_acc)\n",
    "        p = pos / (pos + neg)\n",
    "        # print(f'{p} {pos} {neg}')\n",
    "        return max(1e-100, min(1.0, p))\n",
    "\n",
    "    return compute\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "bdb70c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_class_isolating_posterior(category, *args, **kwargs):\n",
    "    nb_compute = compute_naive_bayes_posterior(*args, **kwargs)\n",
    "\n",
    "    def compute(\n",
    "        dest,\n",
    "        dest_count,\n",
    "        source_counts,\n",
    "    ):\n",
    "        return nb_compute(dest, dest_count, [t for t in source_counts if t[0][1] == category])\n",
    "    return compute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6492e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_max_posterior(\n",
    "    prior_numerator,\n",
    "    prior_denominator,\n",
    "    feature_prior_numerator,\n",
    "    feature_prior_denomenator,\n",
    "):\n",
    "    def compute(\n",
    "        dest,\n",
    "        dest_count,\n",
    "        source_counts,\n",
    "    ):\n",
    "        p = (prior_numerator + dest_count.count) / (\n",
    "            prior_denominator + dest_count.total\n",
    "        )\n",
    "        for (\n",
    "            source,\n",
    "            source_to_pos_dest,\n",
    "            source_to_neg_dest,\n",
    "            neg_source_to_pos_dest,\n",
    "            neg_source_to_neg_dest,\n",
    "        ) in source_counts:\n",
    "            fp = (feature_prior_numerator + source_to_pos_dest.count) / (\n",
    "                feature_prior_denomenator\n",
    "                + source_to_pos_dest.count\n",
    "                + source_to_neg_dest.count\n",
    "            )\n",
    "            p = max(p, fp)\n",
    "        return p\n",
    "\n",
    "    return compute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ca706233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_posterior(\n",
    "    prior_numerator,\n",
    "    prior_denominator,\n",
    "    feature_prior_numerator,\n",
    "    feature_prior_denomenator,\n",
    "):\n",
    "    def compute(\n",
    "        dest,\n",
    "        dest_count,\n",
    "        source_counts,\n",
    "    ):\n",
    "        p = (prior_numerator + dest_count.count) / (\n",
    "            prior_denominator + dest_count.total\n",
    "        )\n",
    "        n = 1\n",
    "        for (\n",
    "            source,\n",
    "            source_to_pos_dest,\n",
    "            source_to_neg_dest,\n",
    "            neg_source_to_pos_dest,\n",
    "            neg_source_to_neg_dest,\n",
    "        ) in source_counts:\n",
    "            fp = (feature_prior_numerator + source_to_pos_dest.count) / (\n",
    "                feature_prior_denomenator\n",
    "                + source_to_pos_dest.count\n",
    "                + source_to_neg_dest.count\n",
    "            )\n",
    "            p += fp\n",
    "            n += 1\n",
    "        return p / n\n",
    "\n",
    "    return compute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e6ec9d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_combined_posterior(\n",
    "    prior_numerator,\n",
    "    prior_denominator,\n",
    "):\n",
    "    def compute(\n",
    "        dest,\n",
    "        dest_count,\n",
    "        source_counts,\n",
    "    ):\n",
    "        numerator = prior_numerator + dest_count.count\n",
    "        denominator = prior_denominator + dest_count.total\n",
    "        for (\n",
    "            source,\n",
    "            source_to_pos_dest,\n",
    "            source_to_neg_dest,\n",
    "            neg_source_to_pos_dest,\n",
    "            neg_source_to_neg_dest,\n",
    "        ) in source_counts:\n",
    "            numerator += source_to_pos_dest.count\n",
    "            denominator += source_to_pos_dest.count + source_to_neg_dest.count\n",
    "        return numerator / denominator\n",
    "\n",
    "    return compute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "aaffca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bayes_posterior(\n",
    "    prior_numerator,\n",
    "    prior_denominator,\n",
    "):\n",
    "    def compute(\n",
    "        dest,\n",
    "        dest_count,\n",
    "        source_counts,\n",
    "    ):\n",
    "        numerator = prior_numerator + dest_count.count\n",
    "        denominator = prior_denominator + dest_count.total\n",
    "        return numerator / denominator\n",
    "\n",
    "    return compute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "afda4f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class Evaluation():\n",
    "    name:str\n",
    "    score:float\n",
    "    positives:float\n",
    "    negatives:float\n",
    "\n",
    "@dataclass\n",
    "class ScoreSummary():\n",
    "    dynamic:List[Evaluation]\n",
    "    dynamic_ndcg:float\n",
    "    # static:List[Evaluation]\n",
    "    # static_ndcg:float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "699c273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_evaluations(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    scoring_function,\n",
    "    evaluation_functions,\n",
    "):\n",
    "    action_indicies = []\n",
    "    num_conditioning_actions_list = []\n",
    "    evaluation_data = [(*t, []) for t in evaluation_functions]\n",
    "\n",
    "    # action_attrs = ('user_id', 'timestamp', 'positive')\n",
    "\n",
    "    for user_id, test_actions in test_df.groupby('user_id'):\n",
    "        train_user_actions = train_df[train_df['user_id'] == user_id]\n",
    "\n",
    "        get_conditioning_actions = None\n",
    "        if train_user_actions['timestamp'].max() < test_actions['timestamp'].min():\n",
    "            # static mode\n",
    "            conditioning_actions_ = list(make_action_sequence(train_user_actions))\n",
    "            get_conditioning_actions = lambda action_row : conditioning_actions_\n",
    "        else:\n",
    "            # dynamic mode\n",
    "            get_conditioning_actions = lambda action_row : list(make_action_sequence(\n",
    "                    train_user_actions[train_user_actions['timestamp'] < action_row['timestamp']]))\n",
    "        \n",
    "        action_indicies.extend(test_actions.index)\n",
    "        # print(test_actions.loc[test_actions.index].head())\n",
    "        \n",
    "        for idx, action_row in test_actions.iterrows():\n",
    "            conditioning_actions = get_conditioning_actions(action_row)\n",
    "            action = make_action_tuple(action_row)\n",
    "            score = scoring_function(\n",
    "                    conditioning_actions,\n",
    "                    action,\n",
    "                )\n",
    "            \n",
    "            num_conditioning_actions_list.append(len(conditioning_actions))\n",
    "            for name, evaluation_func, evaluations in evaluation_data:\n",
    "                evaluations.append(evaluation_func(score, conditioning_actions, action))\n",
    "\n",
    "    res = test_df.loc[action_indicies]\n",
    "    res['num_conditioning_actions'] = num_conditioning_actions_list\n",
    "    for name, evaluation_func, evaluations in evaluation_data:\n",
    "        res[name] = evaluations\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: temporal vs one-shot evaluation\n",
    "# TODO: n-gram temporal prediction vs set-based prediction\n",
    "# TODO: per-rating assesment models\n",
    "\n",
    "'''\n",
    "    + test data: all ratings for user (positive = actual)\n",
    "    + assesment data: assesed conditional pos probability (pos/(pos+neg)) for each test user rating\n",
    "'''\n",
    "\n",
    "def compute_dcg(seq):\n",
    "    # for position, (predicted, actual) in enumerate(seq):\n",
    "    #     print(f'{position}, {predicted}, {actual} : {position + 2 }, {np.log(position + 2)}, {1.0 / np.log(position + 2)}')\n",
    "    return sum((\n",
    "        actual / np.log(position + 2)\n",
    "        for position, (predicted, actual) in enumerate(seq)\n",
    "    ))\n",
    "\n",
    "def compute_ndcg(seq):\n",
    "    dcg = compute_dcg(sorted(seq, reverse=True))\n",
    "    idcg = compute_dcg(sorted((\n",
    "            (actual, actual)\n",
    "            for predicted, actual in seq),\n",
    "        reverse=True))\n",
    "    if idcg <= 1e-6:\n",
    "        return 1.0\n",
    "    #   print(f'dcg: {dcg} / idcg: {idcg}  ; {len(seq)}')  \n",
    "    # print(f'dcg: {dcg} / idcg: {idcg} = ndcg: {dcg / idcg} ; {len(seq)}')\n",
    "    return dcg / idcg\n",
    "\n",
    "# def compute_ndcg_binary(predicted, actual):\n",
    "#     '''\n",
    "#     + actual is 1 or 0\n",
    "#     + dcg is sum(1/np.log(pos+1)) for all true positives\n",
    "#     + idcg is sum(1/np.log(pos+1)) for pos = 1 .. # positive ratings\n",
    "#     '''\n",
    "#     dcg = compute_dcg(\n",
    "#         sorted((\n",
    "#             predicted \n",
    "#             for predicted, actual in seq),\n",
    "#         reverse=True))\n",
    "#     idcg = compute_dcg(\n",
    "#         sorted((\n",
    "#             actual \n",
    "#             for predicted, actual in seq),\n",
    "#         reverse=True))\n",
    "#     return dcg / idcg\n",
    "\n",
    "def compute_ndcg_for_counter(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    scoring_function,\n",
    "):\n",
    "    ndcgs = []\n",
    "    for user_id, test_actions in test_df.groupby('user_id'):\n",
    "        conditioning_actions = list(make_action_sequence(train_df[train_df['user_id'] == user_id]))\n",
    "        user_action_seq = [\n",
    "            (\n",
    "                scoring_function(\n",
    "                    conditioning_actions,\n",
    "                    make_action_tuple(action_row),\n",
    "                ),\n",
    "                action_row['positive'],\n",
    "            )\n",
    "            for idx, action_row in test_actions.iterrows()]\n",
    "        ndcg = compute_ndcg(user_action_seq)\n",
    "        ndcgs.append(ndcg)\n",
    "    return np.mean(ndcgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "47ba8dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: temporal vs one-shot evaluation\n",
    "# TODO: n-gram temporal prediction vs set-based prediction\n",
    "# TODO: per-rating assesment models\n",
    "\n",
    "'''\n",
    "    + test data: all ratings for user (positive = actual)\n",
    "    + assesment data: assesed conditional pos probability (pos/(pos+neg)) for each test user rating\n",
    "'''\n",
    "\n",
    "def compute_dcg(seq):\n",
    "    # for position, (predicted, actual) in enumerate(seq):\n",
    "    #     print(f'{position}, {predicted}, {actual} : {position + 2 }, {np.log(position + 2)}, {1.0 / np.log(position + 2)}')\n",
    "    return sum((\n",
    "        actual / np.log(position + 2)\n",
    "        for position, (predicted, actual) in enumerate(seq)\n",
    "    ))\n",
    "\n",
    "def compute_ndcg(seq):\n",
    "    dcg = compute_dcg(sorted(seq, reverse=True))\n",
    "    idcg = compute_dcg(sorted((\n",
    "            (actual, actual)\n",
    "            for predicted, actual in seq),\n",
    "        reverse=True))\n",
    "    if idcg <= 1e-6:\n",
    "        return 1.0\n",
    "    #   print(f'dcg: {dcg} / idcg: {idcg}  ; {len(seq)}')  \n",
    "    # print(f'dcg: {dcg} / idcg: {idcg} = ndcg: {dcg / idcg} ; {len(seq)}')\n",
    "    return dcg / idcg\n",
    "\n",
    "# def compute_ndcg_binary(predicted, actual):\n",
    "#     '''\n",
    "#     + actual is 1 or 0\n",
    "#     + dcg is sum(1/np.log(pos+1)) for all true positives\n",
    "#     + idcg is sum(1/np.log(pos+1)) for pos = 1 .. # positive ratings\n",
    "#     '''\n",
    "\n",
    "def compute_mean_ndcg(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    scoring_function,\n",
    "):\n",
    "    ndcgs = []\n",
    "    for user_id, test_actions in test_df.groupby('user_id'):\n",
    "        train_user_actions = train_df[train_df['user_id'] == user_id]\n",
    "        \n",
    "        get_conditioning_actions = None\n",
    "        if train_user_actions['timestamp'].max() < test_actions['timestamp'].min():\n",
    "            # static mode\n",
    "            conditioning_actions = list(make_action_sequence(\n",
    "                train_user_actions[train_user_actions['user_id'] == user_id]\n",
    "                ))\n",
    "            get_conditioning_actions = lambda action_row : conditioning_actions\n",
    "        else:\n",
    "            # dynamic mode\n",
    "            get_conditioning_actions = lambda action_row : train_user_actions[train_user_actions['timestamp'] <action_row['timestamp']]\n",
    "        \n",
    "        user_action_seq = [\n",
    "            (\n",
    "                scoring_function(\n",
    "                    get_conditioning_actions(action_row),\n",
    "                    make_action_tuple(action_row),\n",
    "                ),\n",
    "                action_row['positive'],\n",
    "            )\n",
    "            for idx, action_row in test_actions.iterrows()]\n",
    "        ndcg = compute_ndcg(user_action_seq)\n",
    "        ndcgs.append(ndcg)\n",
    "    return np.mean(ndcgs)\n",
    "\n",
    "# TODO: compute and graph distribution based on # of previous ratings and scores (incl iqr/var at each point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4cb6135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_score(log_prob, *args, **kwargs):\n",
    "    return log_prob\n",
    "\n",
    "def brier_score(log_prob, *args, **kwargs):\n",
    "    p = np.exp(log_prob)\n",
    "    return (1 - p) ** 2 + (0 - (1-p)) ** 2\n",
    "\n",
    "def prob_score(log_prob, *args, **kwargs):\n",
    "    return np.exp(log_prob)\n",
    "\n",
    "    \n",
    "def compute_scores(\n",
    "        df,\n",
    "        train_df,\n",
    "        test_df, \n",
    "        assessment_function,\n",
    "    ):\n",
    "    scores = (\n",
    "        ('log', log_score), \n",
    "        ('brier', brier_score),\n",
    "        ('prob', prob_score),\n",
    "    )\n",
    "    \n",
    "    dynamic_evaluations = compute_evaluations(df, test_df, assessment_function, scores)\n",
    "    # static_evaluations = compute_evaluations(train_df, test_df, assessment_function, scores)\n",
    "\n",
    "    def summarize_evaluations(evals):\n",
    "        result = []\n",
    "        for name, _ in scores:\n",
    "            e = evals[name]\n",
    "            result.append(Evaluation(\n",
    "                name,\n",
    "                e.mean(),\n",
    "                e[evals['positive'] == 1].mean(),\n",
    "                e[evals['positive'] == 0].mean(),\n",
    "            ))\n",
    "        return result\n",
    "\n",
    "    return ScoreSummary(\n",
    "        summarize_evaluations(dynamic_evaluations),\n",
    "        compute_mean_ndcg(df, test_df, assessment_function),\n",
    "        # summarize_evaluations(static_evaluations),\n",
    "        # compute_mean_ndcg(train_df, test_df, assessment_function),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0fd6f5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "test_df_sample = test_df.sample(2000)\n",
    "print(len(test_df_sample))\n",
    "pos_df = df[df['positive'] == 1]\n",
    "pos_train_df = train_df[train_df['positive'] == 1]\n",
    "pos_test_df = test_df_sample[test_df_sample['positive'] == 1]\n",
    "\n",
    "neg_df = df[df['positive'] == 0]\n",
    "neg_train_df = train_df[train_df['positive'] == 0]\n",
    "neg_test_df = test_df_sample[test_df_sample['positive'] == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "05a6fc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55975\n"
     ]
    }
   ],
   "source": [
    "pos_bayes = len(train_df[train_df['positive'] == 1]) / len(train_df)\n",
    "print(pos_bayes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f6a87a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to compute NDCG for binary events?\n",
    "# What performance measures should we use here?\n",
    "# How is NDCG computed for ALS?\n",
    "# Next counting model types to investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "70c69e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScoreSummary(dynamic=[Evaluation(name='log',\n",
      "                                 score=-0.24338759838679827,\n",
      "                                 positives=-0.1984257821565767,\n",
      "                                 negatives=-0.2951178600710317),\n",
      "                      Evaluation(name='brier',\n",
      "                                 score=0.12917122790405977,\n",
      "                                 positives=0.1089918761628339,\n",
      "                                 negatives=0.1523883315203089),\n",
      "                      Evaluation(name='prob',\n",
      "                                 score=0.8947647869047793,\n",
      "                                 positives=0.9034055548549438,\n",
      "                                 negatives=0.8848232581879238)],\n",
      "             dynamic_ndcg=0.9712154116395633)\n"
     ]
    }
   ],
   "source": [
    "nb_scores = compute_scores(\n",
    "    df,\n",
    "    train_df,\n",
    "    test_df_sample,\n",
    "    make_assessment_function(compute_naive_bayes_posterior(\n",
    "        pos_bayes * 100,\n",
    "        100,\n",
    "        1e-9,\n",
    "        2e-9,\n",
    "        1e-9,\n",
    "        2e-9,\n",
    "    ), dest_counter, both_counter.link_counter))\n",
    "\n",
    "pprint(nb_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e9557f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScoreSummary(dynamic=[Evaluation(name='log',\n",
      "                                 score=-0.6591703377753474,\n",
      "                                 positives=-0.2783549291734265,\n",
      "                                 negatives=-1.0973127971345469),\n",
      "                      Evaluation(name='brier',\n",
      "                                 score=0.46963278090927063,\n",
      "                                 positives=0.12972288252774072,\n",
      "                                 negatives=0.8607119113052244),\n",
      "                      Evaluation(name='prob',\n",
      "                                 score=0.5724070312824615,\n",
      "                                 positives=0.7631711426070232,\n",
      "                                 negatives=0.3529257419090411)],\n",
      "             dynamic_ndcg=1.0)\n"
     ]
    }
   ],
   "source": [
    "max_scores = compute_scores(\n",
    "    df,\n",
    "    train_df,\n",
    "    test_df_sample,\n",
    "    make_assessment_function(compute_max_posterior(\n",
    "        pos_bayes * 10,\n",
    "        10,\n",
    "        pos_bayes * 10,\n",
    "        10,\n",
    "    ), dest_counter, both_counter.link_counter))\n",
    "pprint(max_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1c0c8854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScoreSummary(dynamic=[Evaluation(name='log',\n",
      "                                 score=-0.5909821179257125,\n",
      "                                 positives=-0.4896732320356205,\n",
      "                                 negatives=-0.7075418038422698),\n",
      "                      Evaluation(name='brier',\n",
      "                                 score=0.4025717637969581,\n",
      "                                 positives=0.30814059407108035,\n",
      "                                 negatives=0.5112183784278065),\n",
      "                      Evaluation(name='prob',\n",
      "                                 score=0.5691641607650249,\n",
      "                                 positives=0.6231365049450509,\n",
      "                                 negatives=0.5070669475686508)],\n",
      "             dynamic_ndcg=1.0)\n"
     ]
    }
   ],
   "source": [
    "avg_scores = compute_scores(\n",
    "    df,\n",
    "    train_df,\n",
    "    test_df_sample,\n",
    "    make_assessment_function(compute_avg_posterior(\n",
    "        pos_bayes * 10,\n",
    "        10,\n",
    "        pos_bayes * 10,\n",
    "        10,\n",
    "    ), dest_counter, both_counter.link_counter))\n",
    "\n",
    "pprint(avg_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5ea19e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScoreSummary(dynamic=[Evaluation(name='log',\n",
      "                                 score=-0.555030349005581,\n",
      "                                 positives=-0.4769878326230674,\n",
      "                                 negatives=-0.6448212011876128),\n",
      "                      Evaluation(name='brier',\n",
      "                                 score=0.37577321263178987,\n",
      "                                 positives=0.303848529895264,\n",
      "                                 negatives=0.45852526696306156),\n",
      "                      Evaluation(name='prob',\n",
      "                                 score=0.6088655217946385,\n",
      "                                 positives=0.6444566186673256,\n",
      "                                 negatives=0.5679166253927295)],\n",
      "             dynamic_ndcg=0.9363226332549881)\n"
     ]
    }
   ],
   "source": [
    "combined_scores = compute_scores(\n",
    "    df,\n",
    "    train_df,\n",
    "    test_df_sample,\n",
    "    make_assessment_function(compute_combined_posterior(\n",
    "        pos_bayes * 10,\n",
    "        10,\n",
    "    ), dest_counter, both_counter.link_counter))\n",
    "\n",
    "pprint(combined_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "3090f402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScoreSummary(dynamic=[Evaluation(name='log',\n",
      "                                 score=-0.6113379964344878,\n",
      "                                 positives=-0.5092882318675327,\n",
      "                                 negatives=-0.7287500911513074),\n",
      "                      Evaluation(name='brier',\n",
      "                                 score=0.4222265724693931,\n",
      "                                 positives=0.3303754964794713,\n",
      "                                 negatives=0.5279046921567225),\n",
      "                      Evaluation(name='prob',\n",
      "                                 score=0.5715370035677586,\n",
      "                                 positives=0.6221446820849407,\n",
      "                                 negatives=0.5133109648436887)],\n",
      "             dynamic_ndcg=0.9363226332549881)\n"
     ]
    }
   ],
   "source": [
    "bayes_scores = compute_scores(\n",
    "    df,\n",
    "    train_df,\n",
    "    test_df_sample,\n",
    "    make_assessment_function(compute_bayes_posterior(\n",
    "        pos_bayes * 10,\n",
    "        10,\n",
    "    ), dest_counter, both_counter.link_counter))\n",
    "\n",
    "pprint(bayes_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "47a9fdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScoreSummary(dynamic=[Evaluation(name='log',\n",
      "                                 score=-0.24338759838679827,\n",
      "                                 positives=-0.1984257821565767,\n",
      "                                 negatives=-0.2951178600710317),\n",
      "                      Evaluation(name='brier',\n",
      "                                 score=0.12917122790405977,\n",
      "                                 positives=0.1089918761628339,\n",
      "                                 negatives=0.1523883315203089),\n",
      "                      Evaluation(name='prob',\n",
      "                                 score=0.8947647869047793,\n",
      "                                 positives=0.9034055548549438,\n",
      "                                 negatives=0.8848232581879238)],\n",
      "             dynamic_ndcg=0.9712154116395633)\n",
      "ScoreSummary(dynamic=[Evaluation(name='log',\n",
      "                                 score=-0.805735447109555,\n",
      "                                 positives=-0.3543507496122633,\n",
      "                                 negatives=-1.3250705291763316),\n",
      "                      Evaluation(name='brier',\n",
      "                                 score=0.24394672058997596,\n",
      "                                 positives=0.137773801000017,\n",
      "                                 negatives=0.3661026603332621),\n",
      "                      Evaluation(name='prob',\n",
      "                                 score=0.836389051496495,\n",
      "                                 positives=0.8872507053537041,\n",
      "                                 negatives=0.7778708045855122)],\n",
      "             dynamic_ndcg=0.9712154116395633)\n"
     ]
    }
   ],
   "source": [
    "inb_scores = compute_scores(\n",
    "    df,\n",
    "    train_df,\n",
    "    test_df_sample,\n",
    "    make_assessment_function(compute_naive_bayes_posterior(\n",
    "        pos_bayes * 100,\n",
    "        100,\n",
    "        1e-9,\n",
    "        2e-9,\n",
    "        1e3,\n",
    "        2e3,\n",
    "    ), dest_counter, both_counter.link_counter))\n",
    "\n",
    "pprint(nb_scores)\n",
    "pprint(inb_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b05086f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScoreSummary(dynamic=[Evaluation(name='log',\n",
      "                                 score=-0.24338759838679827,\n",
      "                                 positives=-0.1984257821565767,\n",
      "                                 negatives=-0.2951178600710317),\n",
      "                      Evaluation(name='brier',\n",
      "                                 score=0.12917122790405977,\n",
      "                                 positives=0.1089918761628339,\n",
      "                                 negatives=0.1523883315203089),\n",
      "                      Evaluation(name='prob',\n",
      "                                 score=0.8947647869047793,\n",
      "                                 positives=0.9034055548549438,\n",
      "                                 negatives=0.8848232581879238)],\n",
      "             dynamic_ndcg=0.9712154116395633)\n",
      "ScoreSummary(dynamic=[Evaluation(name='log',\n",
      "                                 score=-0.26950921099348035,\n",
      "                                 positives=-0.22768041869526953,\n",
      "                                 negatives=-0.31763481073443245),\n",
      "                      Evaluation(name='brier',\n",
      "                                 score=0.13569143647095236,\n",
      "                                 positives=0.11316338444068469,\n",
      "                                 negatives=0.16161080816169046),\n",
      "                      Evaluation(name='prob',\n",
      "                                 score=0.8911928409314194,\n",
      "                                 positives=0.9018300867023935,\n",
      "                                 negatives=0.8789542893454599)],\n",
      "             dynamic_ndcg=0.9363226332549881)\n"
     ]
    }
   ],
   "source": [
    "inb_scores = compute_scores(\n",
    "    df,\n",
    "    train_df,\n",
    "    test_df_sample,\n",
    "    make_assessment_function(compute_naive_bayes_posterior(\n",
    "        pos_bayes * 10,\n",
    "        10,\n",
    "        1e-3,\n",
    "        2e-3,\n",
    "        1e-3,\n",
    "        2e-3,\n",
    "    ), dest_counter, both_counter.link_counter))\n",
    "\n",
    "pprint(nb_scores)\n",
    "pprint(inb_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "83aad71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScoreSummary(dynamic=[Evaluation(name='log',\n",
      "                                 score=-0.24225435328575085,\n",
      "                                 positives=-0.1946272168370058,\n",
      "                                 negatives=-0.29705116618914573),\n",
      "                      Evaluation(name='brier',\n",
      "                                 score=0.12841100228749622,\n",
      "                                 positives=0.10617075846032648,\n",
      "                                 negatives=0.1539992398090786),\n",
      "                      Evaluation(name='prob',\n",
      "                                 score=0.8955275063847118,\n",
      "                                 positives=0.905785754929305,\n",
      "                                 negatives=0.8837250053710403)],\n",
      "             dynamic_ndcg=0.9363226332549881)\n"
     ]
    }
   ],
   "source": [
    "inb_scores = compute_scores(\n",
    "    df,\n",
    "    train_df,\n",
    "    test_df_sample,\n",
    "    make_assessment_function(compute_naive_bayes_posterior(\n",
    "        pos_bayes * 10,\n",
    "        10,\n",
    "        1e-6,\n",
    "        2e-6,\n",
    "        1e-6,\n",
    "        2e-6,\n",
    "    ), dest_counter, both_counter.link_counter))\n",
    "\n",
    "pprint(inb_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f50223a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScoreSummary(dynamic=[Evaluation(name='log',\n",
      "                                 score=-0.24195550952420364,\n",
      "                                 positives=-0.1943116140945185,\n",
      "                                 negatives=-0.29677160426588445),\n",
      "                      Evaluation(name='brier',\n",
      "                                 score=0.12828181032430439,\n",
      "                                 positives=0.10596924597429798,\n",
      "                                 negatives=0.1539532553291505),\n",
      "                      Evaluation(name='prob',\n",
      "                                 score=0.8957238102028348,\n",
      "                                 positives=0.906090965902175,\n",
      "                                 negatives=0.88379600740897)],\n",
      "             dynamic_ndcg=0.9265146724569904)\n"
     ]
    }
   ],
   "source": [
    "inb_scores = compute_scores(\n",
    "    df,\n",
    "    train_df,\n",
    "    test_df_sample,\n",
    "    make_assessment_function(compute_naive_bayes_posterior(\n",
    "        pos_bayes * 1,\n",
    "        1,\n",
    "        1e-6,\n",
    "        2e-6,\n",
    "        1e-6,\n",
    "        2e-6,\n",
    "    ), dest_counter, both_counter.link_counter))\n",
    "\n",
    "pprint(inb_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "4dcd06a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScoreSummary(dynamic=[Evaluation(name='log',\n",
      "                                 score=-0.24109967656291503,\n",
      "                                 positives=-0.19360098004195295,\n",
      "                                 negatives=-0.29574871449563483),\n",
      "                      Evaluation(name='brier',\n",
      "                                 score=0.12778286470473474,\n",
      "                                 positives=0.10550728730712806,\n",
      "                                 negatives=0.15341175482886288),\n",
      "                      Evaluation(name='prob',\n",
      "                                 score=0.896401550631522,\n",
      "                                 positives=0.9066257016131323,\n",
      "                                 negatives=0.8846382801473036)],\n",
      "             dynamic_ndcg=0.9265146724569904)\n"
     ]
    }
   ],
   "source": [
    "inb_scores = compute_scores(\n",
    "    df,\n",
    "    train_df,\n",
    "    test_df_sample,\n",
    "    make_assessment_function(compute_naive_bayes_posterior(\n",
    "        pos_bayes * 1,\n",
    "        1,\n",
    "        1e-9,\n",
    "        2e-9,\n",
    "        1e-9,\n",
    "        2e-9,\n",
    "    ), dest_counter, both_counter.link_counter))\n",
    "\n",
    "pprint(inb_scores)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
